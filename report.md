# Отчет о построении PD - модели

[Ноутбук с кодом и подробными объяснениями](main.ipynb)

## Раздел I. Однофакторный анализ

Для каждого признака (фактора) был расчитан показатель Availability. В результате были выкинуты несколько признаков, у которых данный показатель привысил 80%.

Было произведено WoE преобразование через библиотеку scorecardpy.

Сначала я пытался провести WoE преобразование по алгоритму, изложенному в задании через решающие деревья, но из-за того, что я работю с WoE преобразованием первый раз, попытка не увенчалась успехом.

## Раздел II. Многофакторный анализ

Многофакторный анализ я проводил двумя способами — через линейную регрессию и градиентный бустинг. Рассмотрим подробнее:

### Линейная регрессия

В качестве метрики качества модели использовался коэффициент Джини, который расчитывался как $2 * roc_auc_score - 1$.

Была произведена L1-регуляризация, которая должна была занулить незначимые признаки. В итоге нулевые коэффициенты не появились, поэтому никакие признаки выкинуты не были.

Окончательная модель была построена с помощью линейной регрессии и L2 регуляризации.

Итоговый скор:
- gini_score = 0.20
- roc_auc_score = 0.63

Итоговый скор достаточно низок, так что я решил воспользоваться catboos и градиентным бустингом.

### Градиентный бустинг

Градиентный бустинг я реализовал через catboost, снова используя в качестве метрики коэффициент Джини. Гиперпараметр L2-регуляризации подобрал через grid_search.

Итоговый скор на кросс-валидации:

```
Training on fold [0/5]

bestTest = 0.7820512821
bestIteration = 5

Training on fold [1/5]

bestTest = 0.264957265
bestIteration = 1

Training on fold [2/5]

bestTest = 0.9321305842
bestIteration = 5

Training on fold [3/5]

bestTest = 0.9072164948
bestIteration = 155

Training on fold [4/5]

bestTest = 0.4381443299
bestIteration = 14
```

Видно, что метрица очень сильно разница в зависимости от разбиения, что плохо. Вероятно это вызывается тем, что итоговый датасет сильно несбалланирован.